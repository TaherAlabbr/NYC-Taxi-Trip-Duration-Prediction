# NYC Taxi Trip Duration Prediction: From Feature Engineering to Model Deployment

This project predicts the duration of taxi trips in New York City using supervised machine learning, with a **strong emphasis on feature engineering, model comparison, and real-world deployment**. It is divided into two major phases: the first focuses on EDA and interpretable feature creation using Ridge Regression, and the second benchmarks more advanced modelsâ€”including XGBoost, Neural Networks, and a stacked ensembleâ€”followed by hyperparameter tuning and API deployment.

---

## Project Overview

This project is structured into two main parts:

### â€¢ Part I: Feature Engineering and Baseline Modeling

* Extensive **exploratory data analysis (EDA)** was conducted to identify patterns in spatial, temporal, and behavioral variables.
* More than **30 engineered features** were crafted, ranging from distance metrics and spatial interactions to temporal and behavioral indicators.
* A Ridge Regression model (Î± = 1) was used to **isolate the effect of engineered features** while minimizing the complexity of the model.
* Rigorous **IQR-based outlier removal** was tuned (k = 8) to balance between data cleaning and generalization.
* Log transformation was applied to the target variable (`trip_duration`) to reduce skewness and stabilize model training.

### â€¢ Part II: Model Comparison, Hyperparameter Tuning & API

* Benchmarked multiple models including:

  * Ridge Regression
  * XGBoost
  * Neural Network (PyTorch)
  * A **stacked ensemble** using Ridge & XGBoost as base learners and a Neural Network as the meta-learner
* Conducted **RandomizedSearchCV** for hyperparameter tuning (e.g., `max_depth=13`, `n_estimators=137` for XGBoost).
* **XGBoost** outperformed all other models and was selected for production due to its strong generalization and interpretability.
* A lightweight **API** was developed to serve real-time predictions using the best-performing model.

---

## Dataset

The dataset includes detailed records of NYC taxi trips with attributes such as timestamps, coordinates, and passenger count.

* **Target:** `trip_duration` (in seconds)
* **Features include:**

  * `pickup_latitude`, `pickup_longitude`
  * `dropoff_latitude`, `dropoff_longitude`
  * `passenger_count`, `vendor_id`, and more

---

##  EDA & Feature Engineering Highlights

* **Temporal Patterns:**

  * Trip durations peak in summer and during afternoon rush hours.
  * Weekday effects observed: longer durations midweek, shorter on Sundays.

* **Spatial Insights:**

  * Aggregated `latitude_sum` and `longitude_sum` were more robust than raw coordinates.
  * Pickup/dropoff clustering reflects real-world zones (e.g., Midtown vs. JFK).

* **Outlier Removal via IQR (k = 8):**

  * Experimented with multiple thresholds and empirically selected the one yielding the highest RÂ² without sacrificing valid data.

* **Log-Transforming `trip_duration`:**

  * Improved distribution shape and increased correlation with predictors.

* **Engineered Feature Examples:**

  * Haversine `trip_distance`, its square and log
  * `trip_distance Ã— latitude_sum` / `longitude_sum`
  * Temporal flags: `is_night`, `is_weekend`, `hour Ã— is_night`, `month Ã— is_weekend`
  * Behavioral interactions: `vendor_id Ã— passenger_count`, `trip_distance Ã— weekday`

---

##  Model Performance Overview

### Phase I â€“ Ridge Regression (Î± = 1)

| Dataset        | RÂ² Score | RMSE    |
| -------------- | -------- | ------- |
| Training Set   | 0.68638  | 0.43218 |
| Validation Set | 0.68688  | 0.43290 |

### Phase II â€“ Final Model Comparison

| Model            | Val RÂ² | Val RMSE | Comments                        |
| ---------------- | ------ | -------- | ------------------------------- |
| XGBoost          | 0.759  | 0.381    | **Selected for production**     |
| Stacked Ensemble | 0.754  | 0.385    | Good but more complex           |
| Neural Network   | 0.747  | 0.390    | Competitive, less interpretable |
| Ridge Regression | 0.689  | 0.433    | Strong linear baseline          |

### ðŸŽ¯ Final XGBoost Test Results:

| Dataset  | RÂ² Score | RMSE  |
| -------- | -------- | ----- |
| Test Set | 0.759    | 0.380 |

---

## ðŸ“„ Full Report

For in-depth insights including methodology, feature details, visualizations, and model comparison:

ðŸ‘‰ [**Read Full Report (PDF)**](project_report.pdf)

---

## ðŸ“‚ Project Structure

```
NYC-Taxi-Trip-Duration/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ trip_duration.ipynb
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ project_report.pdf
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ trip_duration_train.py
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â””â”€â”€ trip_duration_test.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ trip_duration_utils_data.py
â”‚   â”‚   â”œâ”€â”€ trip_duration_utils_preprocess.py
â”‚   â”‚   â”œâ”€â”€ trip_duration_utils_eval.py
â”‚   â”‚   â””â”€â”€ cli_args.py
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ predict_api.py
â””â”€â”€ saved_models/
```

---

## Installation

```bash
pip install -r requirements.txt
```

* Python 3.9+ recommended
* Models and preprocessing steps are version-locked for reproducibility

---

## Tools and Technologies

* Python, pandas, NumPy, datetime
* scikit-learn (preprocessing, Ridge, RandomizedSearchCV)
* XGBoost
* PyTorch (Neural Network + Ensemble)
* matplotlib, seaborn (EDA)
* haversine (geospatial distance)
* Flask / FastAPI (API deployment)

---

## API Deployment

A RESTful API is provided to serve model predictions:

```bash
python scripts/api/predict_api.py
```

* Accepts pickup time, location, and trip features
* Returns predicted `trip_duration`
* See `api/predict_api.py` for usage and sample request format

---

## ðŸ“¬ Contact

**Author:** Taher Alabbar
**Email:** [t.alabbar.ca@gmail.com](mailto:t.alabbar.ca@gmail.com)
[**LinkedIn**](https://www.linkedin.com/in/taher-alabbar/)

Letâ€™s connect if you're interested in ML for real-world problems, interpretable modeling, or data-driven feature design!
